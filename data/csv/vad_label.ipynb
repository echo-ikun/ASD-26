{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# File paths\n",
    "loader_csv_path = \"../csv/train_loader.csv\"\n",
    "orig_csv_path = \"../csv/train_orig.csv\"\n",
    "output_csv_path = \"../csv/train_loader_audio.csv\"\n",
    "\n",
    "# 1. Read train_orig.csv and group entries by (video_id, timestamp)\n",
    "frame_dict = defaultdict(list)\n",
    "with open(orig_csv_path, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)  # skip header\n",
    "    for row in reader:\n",
    "        video_id = row[0]\n",
    "        timestamp = round(float(row[1]), 2)\n",
    "        entity_id = row[7]\n",
    "        label_id = int(row[8])\n",
    "        frame_dict[(video_id, timestamp)].append({\n",
    "            \"entity_id\": entity_id,\n",
    "            \"label_id\": label_id,\n",
    "            \"row\": row\n",
    "        })\n",
    "\n",
    "# 2. Count total lines in train_loader.csv for progress bar\n",
    "with open(loader_csv_path, 'r') as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "# 3. Process train_loader.csv\n",
    "rebuilt_rows = []\n",
    "with open(loader_csv_path, newline='') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in tqdm(reader, total=total_lines, desc=\"Processing entities\"):\n",
    "        entity_id = row[0]\n",
    "        labels_str = row[3]\n",
    "        loader_labels = ast.literal_eval(labels_str)\n",
    "        num_frames_loader = len(loader_labels)\n",
    "\n",
    "        # Find all entries in train_orig.csv belonging to this entity_id\n",
    "        entity_entries = [e for entries in frame_dict.values() for e in entries if e[\"entity_id\"] == entity_id]\n",
    "\n",
    "        if not entity_entries:\n",
    "            print(f\"Warning: {entity_id} not found in train_orig.csv\")\n",
    "            continue\n",
    "\n",
    "        # Sort by timestamp\n",
    "        entity_entries.sort(key=lambda x: round(float(x[\"row\"][1]), 2))\n",
    "\n",
    "        new_labels = []\n",
    "        for e in entity_entries:\n",
    "            video_id = e[\"row\"][0]\n",
    "            timestamp = round(float(e[\"row\"][1]), 2)\n",
    "\n",
    "            # Find all entries belonging to the same frame\n",
    "            same_frame_entries = frame_dict.get((video_id, timestamp), [])\n",
    "\n",
    "            # If at least one label_id=1 â†’ 1, otherwise 0\n",
    "            new_label = 1 if any(entry[\"label_id\"] == 1 for entry in same_frame_entries) else 0\n",
    "            new_labels.append(new_label)\n",
    "\n",
    "        # Check if frame counts match\n",
    "        if len(new_labels) != num_frames_loader:\n",
    "            print(f\"Frame count mismatch for {entity_id}: loader={num_frames_loader}, rebuilt={len(new_labels)}\")\n",
    "\n",
    "        # Build new row\n",
    "        new_row = [\n",
    "            entity_id,\n",
    "            row[1],          # keep original column\n",
    "            row[2],          # keep another column\n",
    "            new_labels,\n",
    "            row[4] if len(row) > 4 else \"\"  # optional column\n",
    "        ]\n",
    "        rebuilt_rows.append(new_row)\n",
    "\n",
    "# 4. Save to new CSV\n",
    "with open(output_csv_path, 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    for row in rebuilt_rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"\\nRebuilt CSV saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4349e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# File paths\n",
    "vad_path = \"../csv/val_loader_vad.csv\"\n",
    "audio_path = \"../csv/val_loader_audio.csv\"\n",
    "output_path = \"../csv/val_loader_merged.csv\"\n",
    "\n",
    "# Read CSV (no header, tab-separated)\n",
    "vad_df = pd.read_csv(vad_path, sep=\"\\t\", header=None)\n",
    "audio_df = pd.read_csv(audio_path, sep=\"\\t\", header=None)\n",
    "\n",
    "# Assign column names\n",
    "vad_df.columns = [\"trackid\", \"col2\", \"col3\", \"labels\", \"col5\"]\n",
    "audio_df.columns = [\"trackid\", \"col2\", \"col3\", \"labels\", \"col5\"]\n",
    "\n",
    "# Convert labels from string to list\n",
    "vad_df[\"labels\"] = vad_df[\"labels\"].apply(lambda x: ast.literal_eval(x))\n",
    "audio_df[\"labels\"] = audio_df[\"labels\"].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Build audio labels dictionary {trackid: labels}\n",
    "audio_dict = dict(zip(audio_df[\"trackid\"], audio_df[\"labels\"]))\n",
    "\n",
    "# Update VAD labels\n",
    "def merge_labels(row):\n",
    "    trackid = row[\"trackid\"]\n",
    "    vad_labels = row[\"labels\"]\n",
    "    if trackid in audio_dict:\n",
    "        audio_labels = audio_dict[trackid]\n",
    "        # Align two sequences and update\n",
    "        merged = [1 if (v == 0 and a == 1) else v for v, a in zip(vad_labels, audio_labels)]\n",
    "        return merged\n",
    "    return vad_labels\n",
    "\n",
    "vad_df[\"labels\"] = vad_df.apply(merge_labels, axis=1)\n",
    "\n",
    "# Save to new CSV\n",
    "vad_df.to_csv(output_path, sep=\"\\t\", index=False, header=False)\n",
    "print(f\"Merging completed, result saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f26badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "# File paths\n",
    "merged_path = \"../csv/val_loader_merged.csv\"\n",
    "audio_path = \"../csv/val_loader_audio.csv\"\n",
    "output_path = \"../csv/val_loader_merged_refined.csv\"\n",
    "\n",
    "# Read CSV\n",
    "merged_df = pd.read_csv(merged_path, sep=\"\\t\", header=None)\n",
    "audio_df = pd.read_csv(audio_path, sep=\"\\t\", header=None)\n",
    "\n",
    "# Add column names for easier manipulation\n",
    "merged_df.columns = [\"trackid\", \"col2\", \"col3\", \"labels\", \"col5\"]\n",
    "audio_df.columns = [\"trackid\", \"col2\", \"col3\", \"labels\", \"col5\"]\n",
    "\n",
    "# Convert labels from string to list\n",
    "merged_df[\"labels\"] = merged_df[\"labels\"].apply(lambda x: ast.literal_eval(x))\n",
    "audio_df[\"labels\"] = audio_df[\"labels\"].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Build audio dictionary\n",
    "audio_dict = dict(zip(audio_df[\"trackid\"], audio_df[\"labels\"]))\n",
    "\n",
    "adjust_count = 0\n",
    "\n",
    "def refine_labels(row):\n",
    "    global adjust_count\n",
    "    tid = row[\"trackid\"]\n",
    "    merged_labels = row[\"labels\"]\n",
    "    if tid not in audio_dict:\n",
    "        return merged_labels\n",
    "    \n",
    "    audio_labels = audio_dict[tid]\n",
    "    merged_labels = merged_labels[:]  # Copy\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(merged_labels):\n",
    "        if merged_labels[i] == 1 and audio_labels[i] == 0:\n",
    "            # Found the start of a mismatch segment\n",
    "            start = i\n",
    "            while i < len(merged_labels) and merged_labels[i] == 1 and audio_labels[i] == 0:\n",
    "                i += 1\n",
    "            end = i  # End of the segment (exclusive)\n",
    "            seg_len = end - start\n",
    "            if seg_len <= 6:\n",
    "                for j in range(start, end):\n",
    "                    merged_labels[j] = 0\n",
    "                adjust_count += seg_len\n",
    "        else:\n",
    "            i += 1\n",
    "    return merged_labels\n",
    "\n",
    "# Apply tqdm progress bar\n",
    "tqdm.pandas(desc=\"Refining labels\")\n",
    "merged_df[\"labels\"] = merged_df.progress_apply(refine_labels, axis=1)\n",
    "\n",
    "# Save to new file\n",
    "merged_df.to_csv(output_path, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "print(f\"Refinement completed, new file saved to {output_path}\")\n",
    "print(f\"A total of {adjust_count} labels were adjusted\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
